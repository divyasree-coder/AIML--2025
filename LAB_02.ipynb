{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwsfRz3QYHRBjg/zTNLUoQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyasree-coder/AIML--2025/blob/main/LAB_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-yGK0V4u_pc",
        "outputId": "5724b36b-9601-445c-f12a-49b4c1d96f54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "# Install gym if not already installed\n",
        "!pip install gymnasium\n",
        "\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from collections import defaultdict\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"Blackjack-v1\", sab=True)"
      ],
      "metadata": {
        "id": "VlBjtD02_7jp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mc_policy_evaluation(policy, env, num_episodes=100000, gamma=1.0):\n",
        "    returns_sum = defaultdict(float)\n",
        "    returns_count = defaultdict(int)\n",
        "    V = defaultdict(float)\n",
        "\n",
        "    for _ in range(num_episodes):\n",
        "        episode = []\n",
        "        state, _ = env.reset()\n",
        "        while True:\n",
        "            action = policy(state)\n",
        "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "            episode.append((state, action, reward))\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "            state = next_state\n",
        "\n",
        "        G = 0\n",
        "        visited = set()\n",
        "        for t in reversed(range(len(episode))):\n",
        "            state, action, reward = episode[t]\n",
        "            G = gamma * G + reward\n",
        "            if state not in visited:\n",
        "                returns_sum[state] += G\n",
        "                returns_count[state] += 1\n",
        "                V[state] = returns_sum[state] / returns_count[state]\n",
        "                visited.add(state)\n",
        "    return V\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def simple_policy(state):\n",
        "    player_sum, dealer_card, usable_ace = state\n",
        "    return 0 if player_sum >= 20 else 1  # 0 = stick, 1 = hit\n",
        "\n",
        "\n",
        "\n",
        "def mc_control_epsilon_greedy(env, num_episodes=100000, gamma=1.0, epsilon=0.1):\n",
        "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    returns_sum = defaultdict(float)\n",
        "    returns_count = defaultdict(float)\n",
        "    policy = defaultdict(int)\n",
        "\n",
        "    for _ in range(num_episodes):\n",
        "        episode = []\n",
        "        state, _ = env.reset()\n",
        "        while True:\n",
        "            probs = np.ones(env.action_space.n) * epsilon / env.action_space.n\n",
        "            best_action = np.argmax(Q[state])\n",
        "            probs[best_action] += (1.0 - epsilon)\n",
        "            action = np.random.choice(np.arange(env.action_space.n), p=probs)\n",
        "\n",
        "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "            episode.append((state, action, reward))\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "            state = next_state\n",
        "\n",
        "        G = 0\n",
        "        visited = set()\n",
        "        for t in reversed(range(len(episode))):\n",
        "            state, action, reward = episode[t]\n",
        "            G = gamma * G + reward\n",
        "            if (state, action) not in visited:\n",
        "                returns_sum[(state, action)] += G\n",
        "                returns_count[(state, action)] += 1\n",
        "                Q[state][action] = returns_sum[(state, action)] / returns_count[(state, action)]\n",
        "                visited.add((state, action))\n",
        "\n",
        "    for state in Q:\n",
        "        policy[state] = np.argmax(Q[state])\n",
        "    return policy, Q\n",
        "\n",
        "\n",
        "\n",
        "# Policy Evaluation\n",
        "V = mc_policy_evaluation(simple_policy, env)\n",
        "print(\"Value of state (20, 10, False):\", V[(20, 10, False)])\n",
        "\n",
        "# Policy Control\n",
        "policy, Q = mc_control_epsilon_greedy(env)\n",
        "print(\"Best action for state (20, 10, False):\", policy[(20, 10, False)])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTJl06OA_8yK",
        "outputId": "c4ebd5a7-eb60-4069-f374-da0a165b5948"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value of state (20, 10, False): 0.4171390463487829\n",
            "Best action for state (20, 10, False): 0\n"
          ]
        }
      ]
    }
  ]
}